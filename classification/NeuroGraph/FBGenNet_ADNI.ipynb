{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import  TensorDataset, random_split\n",
    "from torch_geometric.loader import DataLoader \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adni_data_normalized():\n",
    "    argss = {\n",
    "        'dataset_dir': '../../data/ADNI/'\n",
    "    }\n",
    "    args = argparse.Namespace(**argss)\n",
    "    fMRI_path = args.dataset_dir + \"fmri_signal.mat\"\n",
    "    ICV_path = args.dataset_dir + \"ICV.mat\"\n",
    "    AGE_path = args.dataset_dir + \"AGE.mat\"\n",
    "    DX_path = args.dataset_dir + \"DX.mat\"\n",
    "    gender_path = args.dataset_dir + \"gender.mat\"\n",
    "    fMRI_data_path = args.dataset_dir + \"fMRIdata_ADNI2_ADNI3.csv\"\n",
    "    # participants_path = r'./data/ADNI/participants.tsv'\n",
    "\n",
    "    # read fMRI_path\n",
    "    fmri_data = scipy.io.loadmat(fMRI_path)['fmri_signal']\n",
    "    fMRI_data = [fmri_data[i][0] for i in range(len(fmri_data))]\n",
    "\n",
    "    # read ICV_path\n",
    "    icv_data = scipy.io.loadmat(ICV_path)['ICV']\n",
    "    ICV_data = pd.DataFrame([icv_data[i][0] for i in range(len(icv_data))])\n",
    "\n",
    "    # read AGE_path\n",
    "    age_data = scipy.io.loadmat(AGE_path)['AGE']\n",
    "    AGE_data = pd.DataFrame([age_data[i][0] for i in range(len(age_data))])\n",
    "\n",
    "    # read gender_path\n",
    "    gender_data = scipy.io.loadmat(gender_path)['gender']\n",
    "    gender_data = pd.DataFrame([gender_data[i][0] for i in range(len(gender_data))])\n",
    "\n",
    "    # read DX_path\n",
    "    dx_data = scipy.io.loadmat(DX_path)['DX']\n",
    "    DX_data = pd.DataFrame([dx_data[i][0] for i in range(len(dx_data))])\n",
    "\n",
    "    # for all above variable, add a df.insert(0, 'Image_ID', range(1, 1 + len(fMRI_data))) to add Image_ID column\n",
    "    for df in [ICV_data, AGE_data, gender_data, DX_data]:\n",
    "        df.insert(0, 'Image_ID', range(1, 1 + len(fMRI_data)))\n",
    "\n",
    "    # give their column names, EstimatedTotalIntraCranialVol, Age, Gender, Diagnosis\n",
    "    ICV_data.columns = ['Image_ID', 'EstimatedTotalIntraCranialVol']\n",
    "    AGE_data.columns = ['Image_ID', 'Age']\n",
    "    gender_data.columns = ['Image_ID', 'Gender']\n",
    "    DX_data.columns = ['Image_ID', 'Diagnosis']\n",
    "    Image_ID = ICV_data['Image_ID']\n",
    "\n",
    "    data_dict = {\n",
    "        'fMRI_data': fMRI_data,\n",
    "        'ICV_data': ICV_data,\n",
    "        'AGE_data': AGE_data,\n",
    "        'gender_data': gender_data,\n",
    "        'DX_data': DX_data\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_data = read_adni_data_normalized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([579, 50, 100])\n",
      "ys shape: torch.Size([579])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels_file = '../../data/ADNI/y.csv'\n",
    "labels_df = pd.read_csv(labels_file)\n",
    "fMRI_data = adni_data['fMRI_data']\n",
    "ICV_data = adni_data['ICV_data']\n",
    "AGE_data = adni_data['AGE_data']\n",
    "gender_data = adni_data['gender_data']\n",
    "DX_data = adni_data['DX_data']\n",
    "\n",
    "# only keep healthy control and AD. namely 2 and 0\n",
    "labels_df = labels_df[labels_df['Diagnosis'].isin([2, 0])].reset_index(drop=True)\n",
    "# change all 2 to 1\n",
    "labels_df['Diagnosis'] = labels_df['Diagnosis'].replace({2: 1})\n",
    "\n",
    "X = []\n",
    "ys = []\n",
    "\n",
    "# Traverse the labels_df by index i\n",
    "for i in range(len(labels_df)):\n",
    "    IID = labels_df['IID'][i]\n",
    "    y = labels_df['Diagnosis'][i]\n",
    "    \n",
    "    # Get the fMRI data for the subject\n",
    "    subject_data = fMRI_data[IID]\n",
    "    \n",
    "    # Replace zeros with ones\n",
    "    subject_data[subject_data == 0] = 1\n",
    "    \n",
    "    # Z-score normalization for each column of each subject\n",
    "    subject_data = (subject_data - np.mean(subject_data, axis=0)) / np.std(subject_data, axis=0)\n",
    "\n",
    "    # each get first 140 time points\n",
    "    subject_data = subject_data[:50, :]\n",
    "    \n",
    "    # Convert the subject data to a tensor and append it to the list X\n",
    "    X.append(torch.tensor(subject_data, dtype=torch.float))\n",
    "    \n",
    "    # Append the label to the ys list\n",
    "    ys.append(y)\n",
    "\n",
    "# Stack all the tensors in X into a single tensor\n",
    "X = torch.stack(X)  # Shape will be (num_subjects, num_features, ...)\n",
    "\n",
    "# Convert ys to a tensor\n",
    "ys = torch.tensor(ys, dtype=torch.long)\n",
    "\n",
    "# X and ys are now tensors\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"ys shape:\", ys.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesEncoder(nn.Module):\n",
    "    def __init__(self, num_rois, time_steps, embedding_size):\n",
    "        super(TimeSeriesEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_rois, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=embedding_size, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, time_steps, num_rois)\n",
    "        # print('x 1 step', x.size())  # Debugging output\n",
    "        x = F.relu(self.conv1(x))  # Convolution expects 'in_channels = num_rois'\n",
    "        # print('x 2 step', x.size())  # Debugging output\n",
    "        x = self.pool(x)\n",
    "        # print('x 3 step', x.size())  # Debugging output\n",
    "        x = F.relu(self.conv2(x))  # Convolution reduces channels to 'embedding_size'\n",
    "        # print('x 4 step', x.size())  # Debugging output\n",
    "        x = self.pool(x)\n",
    "        # print('x 5 step', x.size())  # Debugging output\n",
    "        x = x.permute(0, 2, 1)  # Permute back to (batch_size, reduced_num_rois, embedding_size)\n",
    "        # print('x 6 step', x.size())  # Debugging output\n",
    "        return x\n",
    "\n",
    "\n",
    "# Graph Generator\n",
    "class GraphGenerator(nn.Module):\n",
    "    def __init__(self, embedding_size, num_rois):\n",
    "        super(GraphGenerator, self).__init__()\n",
    "        self.fc = nn.Linear(embedding_size, num_rois)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hA = F.softmax(self.fc(x), dim=-1)\n",
    "        A = torch.bmm(hA, hA.transpose(1, 2))\n",
    "        return A\n",
    "\n",
    "# Graph Predictor using GCN\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# End-to-end model\n",
    "class FBNetGen(nn.Module):\n",
    "    def __init__(self, num_rois, time_steps, embedding_size, hidden_channels, num_classes):\n",
    "        super(FBNetGen, self).__init__()\n",
    "        self.encoder = TimeSeriesEncoder(num_rois, time_steps, embedding_size)\n",
    "        self.graph_generator = GraphGenerator(embedding_size, num_rois)\n",
    "        self.gcn = GCN(embedding_size, hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('x 1', x.shape)\n",
    "        x = self.encoder(x)\n",
    "        # print('x 2', x.shape)\n",
    "        A = self.graph_generator(x)\n",
    "        # print('A', A.shape)\n",
    "        node_features = x.reshape(-1, x.size(2))  # Flatten to (num_samples * num_rois, embedding_size)\n",
    "        num_nodes = node_features.size(0)\n",
    "        edge_index = torch.randint(0, num_nodes, (2, 500)).to(x.device)  # Ensure edge_index matches the number of nodes\n",
    "\n",
    "        # Adjust the batch tensor to match the flattened node_features\n",
    "        batch = torch.repeat_interleave(torch.arange(x.size(0)), x.size(1)).to(x.device)\n",
    "\n",
    "        output = self.gcn(node_features, edge_index, batch)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# X,y = generate_complex_patterned_data(1000, 10, 120)\n",
    "# dataset = TensorDataset(X, y)\n",
    "# batch_size = 32\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Loss: 0.5413\n",
      "Epoch 40/200, Loss: 0.5355\n",
      "Epoch 60/200, Loss: 0.5244\n",
      "Epoch 80/200, Loss: 0.5283\n",
      "Epoch 100/200, Loss: 0.5047\n",
      "Epoch 120/200, Loss: 0.4390\n",
      "Epoch 140/200, Loss: 0.3906\n",
      "Epoch 160/200, Loss: 0.3188\n",
      "Epoch 180/200, Loss: 0.2883\n",
      "Epoch 200/200, Loss: 0.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 71.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6207\n",
      "F1 Score: 0.7556\n",
      "AUROC: 0.4702\n",
      "Sensitivity: 0.8193\n",
      "Specificity: 0.1212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "# num_samples = 1000\n",
    "num_rois = 100\n",
    "time_steps = 50\n",
    "embedding_size = 16\n",
    "hidden_channels = 64\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Generate patterned data\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FBNetGen(num_rois, time_steps, embedding_size, hidden_channels, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop with tqdm\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # for X_batch, y_batch in train_loader:\n",
    "    # with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "    #     for X_batch, y_batch in tepoch:\n",
    "            # tepoch.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        # tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    # print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}') # with flush\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Evaluation with tqdm\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, unit=\"batch\") as ttest:\n",
    "        for X_batch, y_batch in ttest:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y_batch)\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "# Metrics Calculation\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "auroc = roc_auc_score(all_labels, all_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'AUROC: {auroc:.4f}')\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-1.0790, -1.6929, -1.1463,  ...,  0.4162, -0.6378,  0.1779],\n",
      "         [-0.1744, -0.0126, -0.4268,  ...,  1.0236, -0.1680,  0.6776],\n",
      "         [ 0.5021,  0.7596,  0.4689,  ...,  0.7910,  0.5980,  0.7352],\n",
      "         ...,\n",
      "         [ 0.3452, -0.1843, -1.2420,  ...,  0.5222, -1.0048,  1.0349],\n",
      "         [-0.2712,  0.1095, -0.3691,  ...,  0.8000,  0.1274,  1.2421],\n",
      "         [-0.6005,  0.2217,  0.5570,  ...,  1.0520,  2.0189,  1.3398]],\n",
      "\n",
      "        [[ 0.6050, -0.0868,  0.6044,  ...,  0.2025, -0.1426,  0.3498],\n",
      "         [-2.0480, -0.4314, -1.0616,  ...,  0.1661, -0.0222,  0.1519],\n",
      "         [-2.0345, -0.5252, -1.0195,  ...,  0.0949, -0.2922,  0.0774],\n",
      "         ...,\n",
      "         [ 0.4958, -0.4533, -0.8365,  ..., -1.0103, -0.3615, -0.8292],\n",
      "         [ 1.5971,  0.2116, -0.5327,  ..., -1.2389,  0.6867, -0.5208],\n",
      "         [ 0.5321, -0.0843, -0.6049,  ..., -1.4190,  0.9359, -0.6442]],\n",
      "\n",
      "        [[ 1.2948, -2.7925, -1.1588,  ..., -2.0441, -0.6034, -2.4449],\n",
      "         [-1.5527,  1.7589,  0.5280,  ...,  1.0229, -0.3832,  0.2129],\n",
      "         [-1.5017,  3.0045,  0.8799,  ...,  1.4400, -0.2597,  1.1200],\n",
      "         ...,\n",
      "         [-0.9602,  0.2028,  0.5397,  ..., -0.8976, -0.4317, -0.1718],\n",
      "         [-1.7974, -0.6102, -0.6540,  ..., -0.9877, -1.5292, -0.0691],\n",
      "         [-1.2256, -0.7964, -0.4814,  ..., -0.4528, -0.9877,  0.2129]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2772,  0.2409,  0.6750,  ..., -0.4424,  0.0622, -0.1658],\n",
      "         [-1.8131,  0.1286, -0.6535,  ...,  1.4772,  0.1075,  0.7187],\n",
      "         [-1.9426,  0.1491, -0.6002,  ...,  1.0245,  0.0804,  0.6287],\n",
      "         ...,\n",
      "         [ 0.6382,  1.2903, -0.3876,  ...,  1.3572,  0.1960,  2.1142],\n",
      "         [ 0.3154,  0.8518, -0.2752,  ..., -0.1349,  0.2057,  0.6357],\n",
      "         [ 0.6215,  0.2071,  0.5562,  ..., -1.4997, -0.1045, -1.1862]],\n",
      "\n",
      "        [[-0.6646, -0.7768, -1.3709,  ..., -1.5376, -2.0648, -1.2559],\n",
      "         [ 0.5943, -0.6091,  0.7496,  ...,  0.2518,  1.1282,  0.8045],\n",
      "         [-0.1452, -0.3723,  1.2930,  ...,  1.0833,  1.1996,  1.4210],\n",
      "         ...,\n",
      "         [-0.3368,  1.0414,  0.4779,  ..., -0.3439, -1.1409, -0.4985],\n",
      "         [-0.2752,  0.5235, -0.2996,  ..., -0.8535, -0.0174,  0.0151],\n",
      "         [-0.3035, -0.7611, -0.7200,  ..., -0.9929,  1.0346,  0.3399]],\n",
      "\n",
      "        [[ 0.4724,  0.6622,  0.0968,  ...,  0.5242,  0.2039,  0.3447],\n",
      "         [ 0.1012, -0.2242,  0.6628,  ...,  0.4639, -0.6663, -0.7257],\n",
      "         [-0.0504, -0.2000,  0.3975,  ...,  0.4875, -0.3646, -0.3019],\n",
      "         ...,\n",
      "         [ 0.2400, -0.4589, -1.0366,  ...,  0.1192,  1.1194,  1.0457],\n",
      "         [-0.7749,  0.5409, -1.8279,  ..., -1.3156,  0.2887, -0.2076],\n",
      "         [-1.7263,  0.7114, -2.2458,  ..., -2.1759, -1.1344, -1.6555]]]), tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tepoch:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 9\u001b[0m     X_batch, y_batch, batch, ptr \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# tepoch.set_description(f\"Epoch {epoch+1}/{epochs}\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop with tqdm\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        # for X_batch, y_batch in tepoch:\n",
    "        for i in tepoch:\n",
    "            print(i)\n",
    "            X_batch, y_batch, batch, ptr = i\n",
    "            # tepoch.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Evaluation with tqdm\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, unit=\"batch\") as ttest:\n",
    "        for X_batch, y_batch in ttest:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(y_batch)\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "# Metrics Calculation\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "auroc = roc_auc_score(all_labels, all_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'AUROC: {auroc:.4f}')\n",
    "print(f'Sensitivity: {sensitivity:.4f}')\n",
    "print(f'Specificity: {specificity:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
